{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import json\n",
    "import os\n",
    "\n",
    "class MultiCameraTennisCalibration:\n",
    "    \"\"\"\n",
    "    Multi-camera calibration using tennis court keypoints.\n",
    "    Demonstrates professional computer vision techniques for sports analysis with multiple cameras.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Standard tennis court dimensions (meters)\n",
    "        self.court_length = 12.0  # Simplified court length\n",
    "        self.court_width = 6.0    # Simplified court width\n",
    "        self.service_line_distance = 3.0  # Distance from net to service line\n",
    "        \n",
    "        # Define 3D court keypoints in world coordinates (court-centered)\n",
    "        self.world_keypoints_3d = self.create_court_keypoints_3d()\n",
    "        \n",
    "    def create_court_keypoints_3d(self):\n",
    "        \"\"\"Create standard tennis court keypoints in 3D world coordinates\"\"\"\n",
    "        keypoints = {}\n",
    "        \n",
    "        # Court corners (ground level z=0)\n",
    "        keypoints['back_left'] = [-self.court_length/2, -self.court_width/2, 0]\n",
    "        keypoints['back_right'] = [-self.court_length/2, self.court_width/2, 0]\n",
    "        keypoints['front_left'] = [self.court_length/2, -self.court_width/2, 0]\n",
    "        keypoints['front_right'] = [self.court_length/2, self.court_width/2, 0]\n",
    "        \n",
    "        # Net line intersections\n",
    "        keypoints['net_left'] = [0, -self.court_width/2, 0]\n",
    "        keypoints['net_right'] = [0, self.court_width/2, 0]\n",
    "        keypoints['net_center'] = [0, 0, 0]\n",
    "        \n",
    "        # Service line intersections\n",
    "        keypoints['service_back_left'] = [-self.service_line_distance, -self.court_width/2, 0]\n",
    "        keypoints['service_back_right'] = [-self.service_line_distance, self.court_width/2, 0]\n",
    "        keypoints['service_front_left'] = [self.service_line_distance, -self.court_width/2, 0]\n",
    "        keypoints['service_front_right'] = [self.service_line_distance, self.court_width/2, 0]\n",
    "        \n",
    "        # Center service line intersections\n",
    "        keypoints['center_service_back'] = [-self.service_line_distance, 0, 0]\n",
    "        keypoints['center_service_front'] = [self.service_line_distance, 0, 0]\n",
    "        \n",
    "        return keypoints\n",
    "\n",
    "    def create_full_court_geometry_3d(self):\n",
    "        \"\"\"Create court geometry for overlay visualization\"\"\"\n",
    "        court_lines = []\n",
    "        \n",
    "        # Court boundary rectangle\n",
    "        court_lines.extend([\n",
    "            [[-self.court_length/2, -self.court_width/2, 0], [-self.court_length/2, self.court_width/2, 0]],  # Left baseline\n",
    "            [[self.court_length/2, -self.court_width/2, 0], [self.court_length/2, self.court_width/2, 0]],    # Right baseline  \n",
    "            [[-self.court_length/2, -self.court_width/2, 0], [self.court_length/2, -self.court_width/2, 0]],  # Bottom sideline\n",
    "            [[-self.court_length/2, self.court_width/2, 0], [self.court_length/2, self.court_width/2, 0]]     # Top sideline\n",
    "        ])\n",
    "        \n",
    "        # Net line\n",
    "        court_lines.append([[0, -self.court_width/2, 0], [0, self.court_width/2, 0]])\n",
    "        \n",
    "        # Service lines\n",
    "        court_lines.extend([\n",
    "            [[-self.service_line_distance, -self.court_width/2, 0], [-self.service_line_distance, self.court_width/2, 0]],  # Left service\n",
    "            [[self.service_line_distance, -self.court_width/2, 0], [self.service_line_distance, self.court_width/2, 0]]     # Right service\n",
    "        ])\n",
    "        \n",
    "        # Center service line\n",
    "        court_lines.append([[-self.service_line_distance, 0, 0], [self.service_line_distance, 0, 0]])\n",
    "        \n",
    "        return court_lines\n",
    "    \n",
    "    def load_detections_from_simulation(self, simulation_data_path=\"../utils/data/simulated/synthetic_scene.npz\"):\n",
    "        \"\"\"\n",
    "        Load detections from your tennis simulation data\n",
    "        \"\"\"\n",
    "        # Load simulation data\n",
    "        data = np.load(simulation_data_path, allow_pickle=True)\n",
    "        camera_poses = data['camera_poses']\n",
    "        intrinsics = data['intrinsics']\n",
    "        \n",
    "        print(f\"Loaded simulation data with {len(camera_poses)} cameras\")\n",
    "        \n",
    "        # For each camera, create synthetic keypoint detections\n",
    "        multi_camera_detections = {}\n",
    "        \n",
    "        for cam_idx in range(len(camera_poses)):\n",
    "            R = camera_poses[cam_idx][:3, :3]\n",
    "            t = camera_poses[cam_idx][:3, 3]\n",
    "            K = intrinsics\n",
    "            \n",
    "            # Project all court keypoints to this camera\n",
    "            detections = self.create_synthetic_detections_for_camera(K, R, t, noise_std=1.0)\n",
    "            \n",
    "            if len(detections) >= 6:  # Need at least 6 points for PnP\n",
    "                multi_camera_detections[f'camera_{cam_idx+1}'] = {\n",
    "                    'detections': detections,\n",
    "                    'K_true': K.copy(),\n",
    "                    'R_true': R.copy(),\n",
    "                    't_true': t.copy()\n",
    "                }\n",
    "                print(f\"Camera {cam_idx+1}: {len(detections)} keypoints visible\")\n",
    "            else:\n",
    "                print(f\"Camera {cam_idx+1}: Only {len(detections)} keypoints visible (need â‰¥6)\")\n",
    "        \n",
    "        return multi_camera_detections\n",
    "            \n",
    "    \n",
    "    def project_points(self, K, R, t, points_3d):\n",
    "        \"\"\"Project 3D points to 2D using camera parameters\"\"\"\n",
    "        # Transform to camera coordinates\n",
    "        points_cam = (R @ points_3d.T).T + t.reshape(1, 3)\n",
    "        \n",
    "        points_2d = np.zeros((len(points_3d), 2))\n",
    "        depths = np.zeros(len(points_3d))\n",
    "        \n",
    "        for i, (x, y, z) in enumerate(points_cam):\n",
    "            depths[i] = z\n",
    "            if z > 0.1:  # Point in front of camera\n",
    "                u = K[0,0] * x/z + K[0,2]\n",
    "                v = K[1,1] * y/z + K[1,2]\n",
    "                points_2d[i] = [u, v]\n",
    "            else:\n",
    "                points_2d[i] = [np.nan, np.nan]\n",
    "        \n",
    "        return points_2d, depths\n",
    "    \n",
    "    def create_synthetic_detections_for_camera(self, K_true, R_true, t_true, noise_std=0.5):\n",
    "        \"\"\"Create synthetic 2D keypoint detections for a single camera\"\"\"\n",
    "        # Convert world keypoints to numpy array\n",
    "        keypoint_names = list(self.world_keypoints_3d.keys())\n",
    "        points_3d = np.array([self.world_keypoints_3d[name] for name in keypoint_names])\n",
    "        \n",
    "        # Project to 2D\n",
    "        points_2d_clean, depths = self.project_points(K_true, R_true, t_true, points_3d)\n",
    "        \n",
    "        # Filter out points behind camera or outside reasonable bounds\n",
    "        valid_mask = (~np.isnan(points_2d_clean).any(axis=1)) & (depths > 0.1)\n",
    "        \n",
    "        # Add realistic noise only to valid points\n",
    "        detections = {}\n",
    "        for i, name in enumerate(keypoint_names):\n",
    "            if valid_mask[i]:\n",
    "                # Check if point is within image bounds (with some margin)\n",
    "                x, y = points_2d_clean[i]\n",
    "                if -100 <= x <= 740 and -100 <= y <= 580:  # 640x480 image with margin\n",
    "                    noise = np.random.normal(0, noise_std, 2)\n",
    "                    points_2d_noisy = points_2d_clean[i] + noise\n",
    "                    \n",
    "                    detections[name] = {\n",
    "                        'point_2d': points_2d_noisy,\n",
    "                        'confidence': 0.7 + 0.3 * np.random.random(),\n",
    "                        'world_3d': self.world_keypoints_3d[name],\n",
    "                        'clean_2d': points_2d_clean[i]\n",
    "                    }\n",
    "                \n",
    "        return detections\n",
    "    \n",
    "    def create_synthetic_multi_camera_data(self):\n",
    "        \"\"\"Create synthetic multi-camera data if simulation data not available\"\"\"\n",
    "        print(\"Creating synthetic multi-camera scenario...\")\n",
    "        \n",
    "        camera_configs = [\n",
    "            {'name': 'camera_1', 'pos': [0.0, -5.0, 3.5], 'target': [0.0, 0.0, 0.5]},\n",
    "            {'name': 'camera_2', 'pos': [-4.0, -3.5, 3.5], 'target': [1.0, 1.5, 0.0]},\n",
    "            {'name': 'camera_3', 'pos': [4.0, -3.5, 3.5], 'target': [-1.0, 1.5, 0.0]}\n",
    "        ]\n",
    "        \n",
    "        multi_camera_detections = {}\n",
    "        \n",
    "        for config in camera_configs:\n",
    "            # Create camera parameters\n",
    "            K_true = np.array([[400, 0, 320], [0, 400, 240], [0, 0, 1]], dtype=np.float64)\n",
    "            \n",
    "            camera_pos = np.array(config['pos'])\n",
    "            target_pos = np.array(config['target'])\n",
    "            \n",
    "            # Calculate camera rotation and translation\n",
    "            look_vector = target_pos - camera_pos\n",
    "            look_vector = look_vector / np.linalg.norm(look_vector)\n",
    "            \n",
    "            world_up = np.array([0, 0, 1])\n",
    "            right = np.cross(look_vector, world_up)\n",
    "            right = right / np.linalg.norm(right)\n",
    "            up = -np.cross(right, look_vector)\n",
    "            \n",
    "            R_true = np.column_stack([right, up, look_vector]).T\n",
    "            t_true = -R_true @ camera_pos\n",
    "            \n",
    "            # Generate detections for this camera\n",
    "            detections = self.create_synthetic_detections_for_camera(K_true, R_true, t_true, noise_std=1.0)\n",
    "            \n",
    "            multi_camera_detections[config['name']] = {\n",
    "                'detections': detections,\n",
    "                'K_true': K_true,\n",
    "                'R_true': R_true,\n",
    "                't_true': t_true\n",
    "            }\n",
    "            \n",
    "            print(f\"{config['name']}: {len(detections)} keypoints detected\")\n",
    "        \n",
    "        return multi_camera_detections\n",
    "    \n",
    "    def calibrate_single_camera_pnp(self, detections, initial_K=None):\n",
    "        \"\"\"Calibrate a single camera using PnP algorithm\"\"\"\n",
    "        if len(detections) < 6:\n",
    "            raise ValueError(f\"Need at least 6 keypoints for PnP, got {len(detections)}\")\n",
    "            \n",
    "        # Extract 2D and 3D points\n",
    "        keypoint_names = list(detections.keys())\n",
    "        points_2d = np.array([detections[name]['point_2d'] for name in keypoint_names], dtype=np.float32)\n",
    "        points_3d = np.array([detections[name]['world_3d'] for name in keypoint_names], dtype=np.float32)\n",
    "        \n",
    "        # Use initial intrinsics guess if provided\n",
    "        if initial_K is None:\n",
    "            fx = fy = 400  # Focal length\n",
    "            cx, cy = 320, 240  # Image center\n",
    "            initial_K = np.array([[fx, 0, cx],\n",
    "                                 [0, fy, cy],\n",
    "                                 [0, 0, 1]], dtype=np.float32)\n",
    "        \n",
    "        # Distortion coefficients (assume minimal distortion)\n",
    "        dist_coeffs = np.zeros(4, dtype=np.float32)\n",
    "        \n",
    "        # Solve PnP\n",
    "        success, rvec, tvec = cv2.solvePnP(points_3d, points_2d, initial_K, dist_coeffs, \n",
    "                                          flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "        \n",
    "        if not success:\n",
    "            raise ValueError(\"PnP solution failed\")\n",
    "            \n",
    "        # Convert rotation vector to matrix\n",
    "        R_estimated, _ = cv2.Rodrigues(rvec)\n",
    "        t_estimated = tvec.flatten()\n",
    "        \n",
    "        return initial_K, R_estimated, t_estimated, success\n",
    "    \n",
    "    def calibrate_multi_camera_bundle_adjustment(self, multi_camera_detections):\n",
    "        \"\"\"Multi-camera bundle adjustment calibration\"\"\"\n",
    "        camera_names = list(multi_camera_detections.keys())\n",
    "        num_cameras = len(camera_names)\n",
    "        \n",
    "        print(f\"\\nPerforming bundle adjustment for {num_cameras} cameras...\")\n",
    "        \n",
    "        # Get initial estimates for all cameras using PnP\n",
    "        initial_calibrations = {}\n",
    "        for cam_name in camera_names:\n",
    "            detections = multi_camera_detections[cam_name]['detections']\n",
    "            try:\n",
    "                K_init, R_init, t_init, success = self.calibrate_single_camera_pnp(detections)\n",
    "                initial_calibrations[cam_name] = {\n",
    "                    'K': K_init, 'R': R_init, 't': t_init, 'success': success\n",
    "                }\n",
    "                print(f\"{cam_name}: PnP successful, {len(detections)} keypoints\")\n",
    "            except Exception as e:\n",
    "                print(f\"{cam_name}: PnP failed - {e}\")\n",
    "                return None, None\n",
    "        \n",
    "        def bundle_adjustment_objective(params):\n",
    "            \"\"\"Bundle adjustment cost function\"\"\"\n",
    "            total_cost = 0\n",
    "            param_idx = 0\n",
    "            \n",
    "            for i, cam_name in enumerate(camera_names):\n",
    "                # Extract camera parameters from optimization vector\n",
    "                fx = params[param_idx]\n",
    "                fy = params[param_idx + 1] \n",
    "                cx = params[param_idx + 2]\n",
    "                cy = params[param_idx + 3]\n",
    "                rvec = params[param_idx + 4:param_idx + 7]\n",
    "                tvec = params[param_idx + 7:param_idx + 10]\n",
    "                param_idx += 10\n",
    "                \n",
    "                # Reconstruct camera matrix and pose\n",
    "                K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "                R, _ = cv2.Rodrigues(rvec)\n",
    "                \n",
    "                # Calculate reprojection error for this camera\n",
    "                detections = multi_camera_detections[cam_name]['detections']\n",
    "                for name, detection in detections.items():\n",
    "                    point_3d = np.array([detection['world_3d']])\n",
    "                    point_2d_proj, _ = self.project_points(K, R, tvec, point_3d)\n",
    "                    \n",
    "                    if not np.isnan(point_2d_proj[0]).any():\n",
    "                        point_2d_obs = detection['point_2d']\n",
    "                        weight = detection['confidence']\n",
    "                        error = weight * np.linalg.norm(point_2d_proj[0] - point_2d_obs)**2\n",
    "                        total_cost += error\n",
    "            \n",
    "            return total_cost\n",
    "        \n",
    "        # Create initial parameter vector\n",
    "        initial_params = []\n",
    "        for cam_name in camera_names:\n",
    "            calib = initial_calibrations[cam_name]\n",
    "            K, R, t = calib['K'], calib['R'], calib['t']\n",
    "            rvec, _ = cv2.Rodrigues(R)\n",
    "            \n",
    "            # Add parameters: fx, fy, cx, cy, rvec(3), tvec(3)\n",
    "            cam_params = [K[0,0], K[1,1], K[0,2], K[1,2]] + rvec.flatten().tolist() + t.tolist()\n",
    "            initial_params.extend(cam_params)\n",
    "        \n",
    "        initial_params = np.array(initial_params)\n",
    "        initial_cost = bundle_adjustment_objective(initial_params)\n",
    "        \n",
    "        # Optimize all cameras simultaneously\n",
    "        print(\"Running bundle adjustment optimization...\")\n",
    "        result = minimize(bundle_adjustment_objective, initial_params, method='L-BFGS-B',\n",
    "                         options={'maxiter': 1000, 'ftol': 1e-9})\n",
    "        \n",
    "        # Extract optimized parameters\n",
    "        optimized_calibrations = {}\n",
    "        param_idx = 0\n",
    "        \n",
    "        for cam_name in camera_names:\n",
    "            params = result.x[param_idx:param_idx+10]\n",
    "            fx, fy, cx, cy = params[:4]\n",
    "            rvec = params[4:7]\n",
    "            tvec = params[7:10]\n",
    "            \n",
    "            K_opt = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "            R_opt, _ = cv2.Rodrigues(rvec)\n",
    "            \n",
    "            optimized_calibrations[cam_name] = {\n",
    "                'K': K_opt,\n",
    "                'R': R_opt,\n",
    "                't': tvec,\n",
    "                'initial_cost': initial_cost,\n",
    "                'final_cost': result.fun\n",
    "            }\n",
    "            param_idx += 10\n",
    "        \n",
    "        return optimized_calibrations, result\n",
    "    \n",
    "    def evaluate_multi_camera_calibration(self, multi_camera_detections, calibrations):\n",
    "        \"\"\"Evaluate calibration quality across all cameras\"\"\"\n",
    "        evaluation = {}\n",
    "        \n",
    "        for cam_name, cam_data in multi_camera_detections.items():\n",
    "            if cam_name not in calibrations:\n",
    "                continue\n",
    "                \n",
    "            detections = cam_data['detections']\n",
    "            K = calibrations[cam_name]['K']\n",
    "            R = calibrations[cam_name]['R']\n",
    "            t = calibrations[cam_name]['t']\n",
    "            \n",
    "            # Calculate errors\n",
    "            errors = []\n",
    "            for name, detection in detections.items():\n",
    "                point_3d = np.array([detection['world_3d']])\n",
    "                point_2d_proj, _ = self.project_points(K, R, t, point_3d)\n",
    "                \n",
    "                if not np.isnan(point_2d_proj[0]).any():\n",
    "                    point_2d_obs = detection['point_2d']\n",
    "                    error = np.linalg.norm(point_2d_proj[0] - point_2d_obs)\n",
    "                    errors.append(error)\n",
    "            \n",
    "            if errors:\n",
    "                evaluation[cam_name] = {\n",
    "                    'mean_error': np.mean(errors),\n",
    "                    'max_error': np.max(errors),\n",
    "                    'std_error': np.std(errors),\n",
    "                    'num_keypoints': len(errors)\n",
    "                }\n",
    "            \n",
    "            # Compare with ground truth if available\n",
    "            if 'K_true' in cam_data:\n",
    "                K_true = cam_data['K_true']\n",
    "                R_true = cam_data['R_true']\n",
    "                t_true = cam_data['t_true']\n",
    "                \n",
    "                # Intrinsic parameter errors\n",
    "                fx_error = abs(K[0,0] - K_true[0,0])\n",
    "                fy_error = abs(K[1,1] - K_true[1,1])\n",
    "                cx_error = abs(K[0,2] - K_true[0,2])\n",
    "                cy_error = abs(K[1,2] - K_true[1,2])\n",
    "                \n",
    "                # Camera position error\n",
    "                pos_true = -R_true.T @ t_true\n",
    "                pos_est = -R.T @ t\n",
    "                pos_error = np.linalg.norm(pos_true - pos_est)\n",
    "                \n",
    "                evaluation[cam_name]['ground_truth_comparison'] = {\n",
    "                    'fx_error': fx_error,\n",
    "                    'fy_error': fy_error,\n",
    "                    'cx_error': cx_error,\n",
    "                    'cy_error': cy_error,\n",
    "                    'position_error_m': pos_error\n",
    "                }\n",
    "        \n",
    "        return evaluation\n",
    "    \n",
    "    def create_court_overlay(self, multi_camera_detections, calibrations, \n",
    "                                         court_images_path=\"/sports-vision/utils/data/simulated/camera_views\"):\n",
    "        \"\"\"\n",
    "        Create overlay visualization comparing original court images with reprojected court lines\n",
    "        \"\"\"\n",
    "        overlay_visualizations = {}\n",
    "        \n",
    "        # Get complete court geometry for overlay\n",
    "        court_lines_3d = self.create_full_court_geometry_3d()\n",
    "        \n",
    "        for cam_name, cam_data in multi_camera_detections.items():\n",
    "            if cam_name not in calibrations:\n",
    "                continue\n",
    "                \n",
    "            # Try to load original court image\n",
    "            cam_number = cam_name.split('_')[1]\n",
    "            original_image_path = os.path.join(court_images_path, f\"cam_{cam_number}_tennis_view.png\")\n",
    "            \n",
    "            if os.path.exists(original_image_path):\n",
    "                # Load original synthetic image\n",
    "                original_image = cv2.imread(original_image_path)\n",
    "                print(f\"Loaded original image: {original_image_path}\")\n",
    "            else:\n",
    "                # Create blank court-like image\n",
    "                original_image = self.create_court_background_image()\n",
    "                print(f\"Created synthetic court background for {cam_name}\")\n",
    "            \n",
    "            # Create overlay image\n",
    "            overlay_image = original_image.copy()\n",
    "            \n",
    "            # Get calibrated camera parameters\n",
    "            K = calibrations[cam_name]['K']\n",
    "            R = calibrations[cam_name]['R']\n",
    "            t = calibrations[cam_name]['t']\n",
    "            \n",
    "            # Project and draw complete court lines using calibrated parameters\n",
    "            print(f\"Projecting court lines for {cam_name}...\")\n",
    "            for line_3d in court_lines_3d:\n",
    "                line_points_3d = np.array(line_3d)\n",
    "                line_points_2d, depths = self.project_points(K, R, t, line_points_3d)\n",
    "                \n",
    "                # Draw line if both endpoints are in front of camera\n",
    "                if np.all(depths > 0.1) and not np.isnan(line_points_2d).any():\n",
    "                    pt1 = tuple(line_points_2d[0].astype(int))\n",
    "                    pt2 = tuple(line_points_2d[1].astype(int))\n",
    "                    \n",
    "                    # Draw reprojected court line in bright color (magenta)\n",
    "                    cv2.line(overlay_image, pt1, pt2, (255, 0, 255), 3)\n",
    "            \n",
    "            # Draw keypoint detections and reprojections\n",
    "            detections = cam_data['detections']\n",
    "            \n",
    "            # Draw detected keypoints (red circles)\n",
    "            for name, detection in detections.items():\n",
    "                pt = tuple(detection['point_2d'].astype(int))\n",
    "                if 0 <= pt[0] < overlay_image.shape[1] and 0 <= pt[1] < overlay_image.shape[0]:\n",
    "                    cv2.circle(overlay_image, pt, 6, (0, 0, 255), -1)  # Red\n",
    "                    cv2.putText(overlay_image, name[:4], (pt[0]+10, pt[1]), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "            \n",
    "            # Draw reprojected keypoints (green circles)\n",
    "            for name, detection in detections.items():\n",
    "                point_3d = np.array([detection['world_3d']])\n",
    "                point_2d_proj, _ = self.project_points(K, R, t, point_3d)\n",
    "                \n",
    "                if not np.isnan(point_2d_proj[0]).any():\n",
    "                    pt_proj = tuple(point_2d_proj[0].astype(int))\n",
    "                    if 0 <= pt_proj[0] < overlay_image.shape[1] and 0 <= pt_proj[1] < overlay_image.shape[0]:\n",
    "                        cv2.circle(overlay_image, pt_proj, 4, (0, 255, 0), -1)  # Green\n",
    "                        \n",
    "                        # Draw error vector (cyan line)\n",
    "                        pt_det = tuple(detection['point_2d'].astype(int))\n",
    "                        cv2.line(overlay_image, pt_det, pt_proj, (255, 255, 0), 2)\n",
    "            \n",
    "            # Add calibration quality info\n",
    "            if cam_name in calibrations:\n",
    "                eval_data = self.evaluate_single_camera(cam_data, calibrations[cam_name])\n",
    "                \n",
    "                # Add text overlay with calibration info\n",
    "                info_text = [\n",
    "                    f\"{cam_name.upper()} - Calibration Overlay\",\n",
    "                    f\"Reprojection Error: {eval_data['mean_error']:.2f}px\",\n",
    "                    f\"Keypoints: {eval_data['num_keypoints']}\",\n",
    "                    \"Magenta: Reprojected Court\",\n",
    "                    \"Red: Detected Keypoints\", \n",
    "                    \"Green: Reprojected Keypoints\",\n",
    "                    \"Cyan: Reprojection Errors\"\n",
    "                ]\n",
    "                \n",
    "                for i, text in enumerate(info_text):\n",
    "                    y_pos = 30 + i * 25\n",
    "                    cv2.putText(overlay_image, text, (10, y_pos), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            overlay_visualizations[cam_name] = overlay_image\n",
    "            \n",
    "        return overlay_visualizations\n",
    "    \n",
    "    def evaluate_single_camera(self, cam_data, calibration):\n",
    "        \"\"\"Evaluate single camera calibration\"\"\"\n",
    "        detections = cam_data['detections']\n",
    "        K = calibration['K']\n",
    "        R = calibration['R']\n",
    "        t = calibration['t']\n",
    "        \n",
    "        errors = []\n",
    "        for name, detection in detections.items():\n",
    "            point_3d = np.array([detection['world_3d']])\n",
    "            point_2d_proj, _ = self.project_points(K, R, t, point_3d)\n",
    "            \n",
    "            if not np.isnan(point_2d_proj[0]).any():\n",
    "                point_2d_obs = detection['point_2d']\n",
    "                error = np.linalg.norm(point_2d_proj[0] - point_2d_obs)\n",
    "                errors.append(error)\n",
    "        \n",
    "        return {\n",
    "            'mean_error': np.mean(errors) if errors else 0,\n",
    "            'max_error': np.max(errors) if errors else 0,\n",
    "            'num_keypoints': len(errors)\n",
    "        }\n",
    "    \n",
    "    def create_court_background_image(self, image_size=(640, 480)):\n",
    "        \"\"\"Create a synthetic court background if original image not available\"\"\"\n",
    "        image = np.zeros((image_size[1], image_size[0], 3), dtype=np.uint8)\n",
    "        \n",
    "        # Sky gradient\n",
    "        for y in range(int(image_size[1] * 0.4)):\n",
    "            intensity = 180 + int((y / (image_size[1] * 0.4)) * 55)\n",
    "            blue = min(255, intensity + 75)\n",
    "            green = min(255, intensity + 26) \n",
    "            red = min(255, intensity - 45)\n",
    "            image[y, :] = [blue, green, red]\n",
    "        \n",
    "        # Court surface (simplified)\n",
    "        court_color = (34, 139, 34)  # Green\n",
    "        cv2.rectangle(image, (0, int(image_size[1]*0.4)), (image_size[0], image_size[1]), court_color, -1)\n",
    "        \n",
    "        return image\n",
    "\n",
    "def multi_camera_calibration():\n",
    "    \"\"\"Complete demonstration of multi-camera calibration with court overlay visualization\"\"\"\n",
    "    \n",
    "    # Initialize calibration system\n",
    "    calibrator = MultiCameraTennisCalibration()\n",
    "    \n",
    "    # 1. Load multi-camera detections\n",
    "    print(\"\\n1. Loading multi-camera court keypoint detections...\")\n",
    "    multi_camera_detections = calibrator.load_detections_from_simulation()\n",
    "    \n",
    "    if not multi_camera_detections:\n",
    "        print(\"No camera detections available!\")\n",
    "        return\n",
    "    \n",
    "    # 2. Perform multi-camera bundle adjustment\n",
    "    print(\"\\n2. Performing multi-camera bundle adjustment calibration...\")\n",
    "    \n",
    "    calibrations, optimization_result = calibrator.calibrate_multi_camera_bundle_adjustment(multi_camera_detections)\n",
    "    \n",
    "    if calibrations is None:\n",
    "        print(\"Multi-camera calibration failed!\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Bundle adjustment converged: {optimization_result.success}\")\n",
    "    print(f\"Initial cost: {list(calibrations.values())[0]['initial_cost']:.2f}\")\n",
    "    print(f\"Final cost: {optimization_result.fun:.2f}\")\n",
    "        \n",
    "    # 3. Evaluate calibration results\n",
    "    print(\"\\n3. Evaluating calibration results...\")\n",
    "    evaluation = calibrator.evaluate_multi_camera_calibration(multi_camera_detections, calibrations)\n",
    "    \n",
    "    # 4. Create court overlay visualizations\n",
    "    print(\"\\n4.Creating court overlay visualizations...\")\n",
    "    overlay_visualizations = calibrator.create_court_overlay(\n",
    "        multi_camera_detections, calibrations)\n",
    "    \n",
    "    for cam_name, overlay_image in overlay_visualizations.items():\n",
    "        filename = f\"tennis_calibration_overlay_{cam_name}.png\"\n",
    "        cv2.imwrite(filename, overlay_image)\n",
    "    \n",
    "    # 5. Print results summary\n",
    "    print(\"\\n5.Calibration Results Summary:\")\n",
    "    for cam_name, eval_data in evaluation.items():\n",
    "        print(f\"\\n{cam_name.upper()}:\")\n",
    "        print(f\"Mean reprojection error: {eval_data['mean_error']:.3f} pixels\")\n",
    "        print(f\"Max reprojection error: {eval_data['max_error']:.3f} pixels\")\n",
    "        print(f\"Keypoints used: {eval_data['num_keypoints']}\")\n",
    "        \n",
    "        if 'ground_truth_comparison' in eval_data:\n",
    "            gt = eval_data['ground_truth_comparison']\n",
    "            print(f\"Ground truth errors:\")\n",
    "            print(f\"Focal length: fx={gt['fx_error']:.2f}, fy={gt['fy_error']:.2f}\")\n",
    "            print(f\"Principal point: cx={gt['cx_error']:.2f}, cy={gt['cy_error']:.2f}\")\n",
    "            print(f\"Position: {gt['position_error_m']:.3f}m\")\n",
    "    \n",
    "    # 6. Save comprehensive results\n",
    "    results = {\n",
    "        'overlay_visualization_info': {\n",
    "            'description': 'Court overlay showing original synthetic images with reprojected court lines',\n",
    "            'color_coding': {\n",
    "                'magenta_lines': 'Reprojected court lines using calibrated parameters',\n",
    "                'red_circles': 'Detected court keypoints (with noise)',\n",
    "                'green_circles': 'Reprojected keypoints using calibrated parameters',\n",
    "                'cyan_lines': 'Reprojection error vectors (detected to reprojected)',\n",
    "                'original_court': 'Original synthetic tennis court from simulation'\n",
    "            },\n",
    "            'interpretation': {\n",
    "                'good_calibration': 'Magenta lines should align well with original court lines',\n",
    "                'keypoint_accuracy': 'Short cyan error lines indicate good calibration',\n",
    "                'overall_quality': 'Visual alignment shows calibration accuracy'\n",
    "            }\n",
    "        },\n",
    "        'multi_camera_calibration': {},\n",
    "        'evaluation': evaluation,\n",
    "        'optimization_info': {\n",
    "            'success': optimization_result.success,\n",
    "            'final_cost': float(optimization_result.fun),\n",
    "            'message': optimization_result.message\n",
    "        },\n",
    "        'techniques_demonstrated': [\n",
    "            'Multi-camera bundle adjustment',\n",
    "            'Court overlay visualization',\n",
    "            'Reprojection error analysis',\n",
    "            'Ground truth validation',\n",
    "            'Visual calibration assessment'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for cam_name, calib in calibrations.items():\n",
    "        camera_position = -calib['R'].T @ calib['t']\n",
    "        results['multi_camera_calibration'][cam_name] = {\n",
    "            'intrinsics': {\n",
    "                'fx': float(calib['K'][0,0]),\n",
    "                'fy': float(calib['K'][1,1]),\n",
    "                'cx': float(calib['K'][0,2]),\n",
    "                'cy': float(calib['K'][1,2])\n",
    "            },\n",
    "            'extrinsics': {\n",
    "                'rotation_matrix': calib['R'].tolist(),\n",
    "                'translation_vector': calib['t'].tolist(),\n",
    "                'camera_position': camera_position.tolist()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    with open('tennis_calibration_overlay_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(\"\\n Saved overlay results: tennis_calibration_overlay_results.json\")\n",
    "    \n",
    "    print(\"\\n Multi-camera calibration with court overlay completed successfully!\")\n",
    "    print(\"Check the overlay images to visually assess calibration quality!\")\n",
    "    \n",
    "    return calibrator, calibrations, multi_camera_detections, overlay_visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_camera_calibration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmcv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
